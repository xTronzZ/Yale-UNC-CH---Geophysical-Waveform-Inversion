{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98fc2ea",
   "metadata": {
    "papermill": {
     "duration": 8.910284,
     "end_time": "2025-05-22T15:58:45.181349",
     "exception": false,
     "start_time": "2025-05-22T15:58:36.271065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RUN_TRAIN = True # bfloat16 or float32 recommended\n",
    "RUN_VALID = True\n",
    "RUN_TEST  = False\n",
    "\n",
    "import torch\n",
    "if not torch.cuda.is_available() or torch.cuda.device_count() < 2:\n",
    "    raise RuntimeError(\"Requires >= 2 GPUs with CUDA enabled.\")\n",
    "\n",
    "try: \n",
    "    import monai\n",
    "except: \n",
    "    !pip install --no-deps monai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6ca75d-e5a2-49d6-8391-517a2cc47825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26accaf8",
   "metadata": {
    "papermill": {
     "duration": 0.004564,
     "end_time": "2025-05-22T15:58:45.191055",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.186491",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ConvNeXt Baseline Notebook\n",
    "\n",
    "This notebook builds on [HGNet-V2 Starter](https://www.kaggle.com/code/brendanartley/hgnet-v2-starter) notebook. I recommend reading that one first, as many components are reused here. The differences here are that we train on the full-size seismic data and adapt a ConvNeXt model for the non-square input shape. \n",
    "\n",
    "In addition, I provide 2x pretrained model checkpoints (trained for 50 epochs), which both achieved a validation MAE of ~34.\n",
    "\n",
    "Other stuff:                                                                 \n",
    "- Activation swaps\n",
    "- Normalization swaps\n",
    "\n",
    "NOTE: ConvNeXt is unstable on float16 (loss becomes NAN). Use bfloat16 or float32 if possible.\n",
    "\n",
    "#### Updates\n",
    "\n",
    "V2: [@Harshitsheoran](https://www.kaggle.com/harshitsheoran) shared some further finetuned weights with the community. Cheers! ðŸ”¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ca39d",
   "metadata": {
    "papermill": {
     "duration": 0.012539,
     "end_time": "2025-05-22T15:58:45.208002",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.195463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting _cfg.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile _cfg.py\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import torch\n",
    "\n",
    "cfg= SimpleNamespace()\n",
    "cfg.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg.local_rank = 0\n",
    "cfg.seed = 123\n",
    "cfg.subsample = None\n",
    "\n",
    "# cfg.backbone = \"convnextv2_base.fcmae_ft_in22k_in1k_384\"\n",
    "# cfg.backbone = \"convnextv2_large.fcmae_ft_in22k_in1k_384\"\n",
    "cfg.backbone = \"convnextv2_huge.fcmae_ft_in22k_in1k_512\"\n",
    "\n",
    "cfg.ema = True\n",
    "cfg.ema_decay = 0.99\n",
    "\n",
    "cfg.epochs = 200\n",
    "cfg.batch_size = 16\n",
    "cfg.batch_size_val = 16\n",
    "\n",
    "cfg.early_stopping = {\"patience\": 10, \"streak\": 0}\n",
    "cfg.logging_steps = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bb849b",
   "metadata": {
    "papermill": {
     "duration": 0.00435,
     "end_time": "2025-05-22T15:58:45.216822",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.212472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset\n",
    "\n",
    "Almost the same as the starter notebook. \n",
    "\n",
    "The input dataset changes to Egor's [openfwi_float16_1](https://www.kaggle.com/datasets/egortrushin/open-wfi-1) and [openfwi_float16_2](https://www.kaggle.com/datasets/egortrushin/open-wfi-2) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd740410",
   "metadata": {
    "papermill": {
     "duration": 0.01164,
     "end_time": "2025-05-22T15:58:45.233128",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.221488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting _dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile _dataset.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cfg,\n",
    "        mode = \"train\", \n",
    "        transform_data=None,\n",
    "    ):\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        \n",
    "        self.data, self.labels, self.records = self.load_metadata()\n",
    "\n",
    "    def load_metadata(self, ):\n",
    "\n",
    "        # Select rows\n",
    "        df= pd.read_csv(\"Data/datesets/brendanartley/openfwi-preprocessed-72x72/versions/7/folds.csv\")\n",
    "        \n",
    "        if self.cfg.subsample is not None:\n",
    "            df= df.groupby([\"dataset\", \"fold\"]).head(self.cfg.subsample)\n",
    "\n",
    "        if self.mode == \"train\":\n",
    "            df= df[df[\"fold\"] != 0]\n",
    "        else:\n",
    "            df= df[df[\"fold\"] == 0]\n",
    "\n",
    "        \n",
    "        data = []\n",
    "        labels = []\n",
    "        records = []\n",
    "        mmap_mode = \"r\"\n",
    "\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), disable=self.cfg.local_rank != 0):\n",
    "            row= row.to_dict()\n",
    "\n",
    "            # Hacky way to get exact file name\n",
    "            p1 = os.path.join(\"Data/datesets/egortrushin/open-wfi-1/versions/1/openfwi_float16_1\", row[\"data_fpath\"])\n",
    "            p2 = os.path.join(\"Data/datesets/egortrushin/open-wfi-1/versions/1/openfwi_float16_1\", row[\"data_fpath\"].split(\"/\")[0], \"*\", row[\"data_fpath\"].split(\"/\")[-1])\n",
    "            p3 = os.path.join(\"Data/datesets/egortrushin/open-wfi-2/versions/1/openfwi_float16_2\", row[\"data_fpath\"])\n",
    "            p4 = os.path.join(\"Data/datesets/egortrushin/open-wfi-2/versions/1/openfwi_float16_2\", row[\"data_fpath\"].split(\"/\")[0], \"*\", row[\"data_fpath\"].split(\"/\")[-1])\n",
    "            farr= glob.glob(p1) + glob.glob(p2) + glob.glob(p3) + glob.glob(p4)\n",
    "        \n",
    "            # Map to lbl fpath\n",
    "            farr= farr[0]\n",
    "            flbl= farr.replace('seis', 'vel').replace('data', 'model')\n",
    "            \n",
    "            # Load\n",
    "            arr= np.load(farr, mmap_mode=mmap_mode)\n",
    "            lbl= np.load(flbl, mmap_mode=mmap_mode)\n",
    "\n",
    "            # Append\n",
    "            data.append(arr)\n",
    "            labels.append(lbl)\n",
    "            records.append(row[\"dataset\"])\n",
    "\n",
    "        return data, labels, records\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row_idx= idx // 500\n",
    "        col_idx= idx % 500\n",
    "\n",
    "        d= self.records[row_idx]\n",
    "        x= self.data[row_idx][col_idx, ...]\n",
    "        y= self.labels[row_idx][col_idx, ...]\n",
    "\n",
    "        # Augs \n",
    "        if self.mode == \"train\":\n",
    "            \n",
    "            # Temporal flip\n",
    "            if np.random.random() < 0.5:\n",
    "                x= x[::-1, :, ::-1]\n",
    "                y= y[..., ::-1]\n",
    "\n",
    "        x= x.copy()\n",
    "        y= y.copy()\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "    def __len__(self, ):\n",
    "        return len(self.records) * 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa86323",
   "metadata": {
    "papermill": {
     "duration": 0.01508,
     "end_time": "2025-05-22T15:58:45.261339",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.246259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting _model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile _model.py\n",
    "\n",
    "from copy import deepcopy\n",
    "from types import MethodType\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "from timm.models.convnext import ConvNeXtBlock\n",
    "\n",
    "from monai.networks.blocks import UpSample, SubpixelUpsample\n",
    "\n",
    "####################\n",
    "## EMA + Ensemble ##\n",
    "####################\n",
    "\n",
    "class ModelEMA(nn.Module):\n",
    "    def __init__(self, model, decay=0.99, device=None):\n",
    "        super().__init__()\n",
    "        self.module = deepcopy(model)\n",
    "        self.module.eval()\n",
    "        self.decay = decay\n",
    "        self.device = device\n",
    "        if self.device is not None:\n",
    "            self.module.to(device=device)\n",
    "\n",
    "    def _update(self, model, update_fn):\n",
    "        with torch.no_grad():\n",
    "            for ema_v, model_v in zip(self.module.state_dict().values(), model.state_dict().values()):\n",
    "                if self.device is not None:\n",
    "                    model_v = model_v.to(device=self.device)\n",
    "                ema_v.copy_(update_fn(ema_v, model_v))\n",
    "\n",
    "    def update(self, model):\n",
    "        self._update(model, update_fn=lambda e, m: self.decay * e + (1. - self.decay) * m)\n",
    "\n",
    "    def set(self, model):\n",
    "        self._update(model, update_fn=lambda e, m: m)\n",
    "\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models = nn.ModuleList(models).eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = None\n",
    "        \n",
    "        for m in self.models:\n",
    "            logits= m(x)\n",
    "            \n",
    "            if output is None:\n",
    "                output = logits\n",
    "            else:\n",
    "                output += logits\n",
    "                \n",
    "        output /= len(self.models)\n",
    "        return output\n",
    "        \n",
    "\n",
    "#############\n",
    "## Decoder ##\n",
    "#############\n",
    "\n",
    "class ConvBnAct2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        padding: int = 0,\n",
    "        stride: int = 1,\n",
    "        norm_layer: nn.Module = nn.Identity,\n",
    "        act_layer: nn.Module = nn.ReLU,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv= nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride, \n",
    "            padding=padding, \n",
    "            bias=False,\n",
    "        )\n",
    "        self.norm = norm_layer(out_channels) if norm_layer != nn.Identity else nn.Identity()\n",
    "        self.act= act_layer(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SCSEModule2d(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.cSE = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, 1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.sSE = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 1, 1), \n",
    "            nn.Sigmoid(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.cSE(x) + x * self.sSE(x)\n",
    "\n",
    "class Attention2d(nn.Module):\n",
    "    def __init__(self, name, **params):\n",
    "        super().__init__()\n",
    "        if name is None:\n",
    "            self.attention = nn.Identity(**params)\n",
    "        elif name == \"scse\":\n",
    "            self.attention = SCSEModule2d(**params)\n",
    "        else:\n",
    "            raise ValueError(\"Attention {} is not implemented\".format(name))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.attention(x)\n",
    "\n",
    "class DecoderBlock2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        skip_channels,\n",
    "        out_channels,\n",
    "        norm_layer: nn.Module = nn.Identity,\n",
    "        attention_type: str = None,\n",
    "        intermediate_conv: bool = False,\n",
    "        upsample_mode: str = \"deconv\",\n",
    "        scale_factor: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Upsample block\n",
    "        if upsample_mode == \"pixelshuffle\":\n",
    "            self.upsample= SubpixelUpsample(\n",
    "                spatial_dims= 2,\n",
    "                in_channels= in_channels,\n",
    "                scale_factor= scale_factor,\n",
    "            )\n",
    "        else:\n",
    "            self.upsample = UpSample(\n",
    "                spatial_dims= 2,\n",
    "                in_channels= in_channels,\n",
    "                out_channels= in_channels,\n",
    "                scale_factor= scale_factor,\n",
    "                mode= upsample_mode,\n",
    "            )\n",
    "\n",
    "        if intermediate_conv:\n",
    "            k= 3\n",
    "            c= skip_channels if skip_channels != 0 else in_channels\n",
    "            self.intermediate_conv = nn.Sequential(\n",
    "                ConvBnAct2d(c, c, k, k//2),\n",
    "                ConvBnAct2d(c, c, k, k//2),\n",
    "                )\n",
    "        else:\n",
    "            self.intermediate_conv= None\n",
    "\n",
    "        self.attention1 = Attention2d(\n",
    "            name= attention_type, \n",
    "            in_channels= in_channels + skip_channels,\n",
    "            )\n",
    "\n",
    "        self.conv1 = ConvBnAct2d(\n",
    "            in_channels + skip_channels,\n",
    "            out_channels,\n",
    "            kernel_size= 3,\n",
    "            padding= 1,\n",
    "            norm_layer= norm_layer,\n",
    "        )\n",
    "\n",
    "        self.conv2 = ConvBnAct2d(\n",
    "            out_channels,\n",
    "            out_channels,\n",
    "            kernel_size= 3,\n",
    "            padding= 1,\n",
    "            norm_layer= norm_layer,\n",
    "        )\n",
    "        self.attention2 = Attention2d(\n",
    "            name= attention_type, \n",
    "            in_channels= out_channels,\n",
    "            )\n",
    "\n",
    "    def forward(self, x, skip=None):\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        if self.intermediate_conv is not None:\n",
    "            if skip is not None:\n",
    "                skip = self.intermediate_conv(skip)\n",
    "            else:\n",
    "                x = self.intermediate_conv(x)\n",
    "\n",
    "        if skip is not None:\n",
    "            # print(x.shape, skip.shape)\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "            x = self.attention1(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.attention2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UnetDecoder2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Unet decoder.\n",
    "    Source: https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_channels: tuple[int],\n",
    "        skip_channels: tuple[int] = None,\n",
    "        decoder_channels: tuple = (256, 128, 64, 32),\n",
    "        scale_factors: tuple = (2,2,2,2),\n",
    "        norm_layer: nn.Module = nn.Identity,\n",
    "        attention_type: str = None,\n",
    "        intermediate_conv: bool = False,\n",
    "        upsample_mode: str = \"deconv\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        if len(encoder_channels) == 4:\n",
    "            decoder_channels= decoder_channels[1:]\n",
    "        self.decoder_channels= decoder_channels\n",
    "        \n",
    "        if skip_channels is None:\n",
    "            skip_channels= list(encoder_channels[1:]) + [0]\n",
    "\n",
    "        # Build decoder blocks\n",
    "        in_channels= [encoder_channels[0]] + list(decoder_channels[:-1])\n",
    "        self.blocks = nn.ModuleList()\n",
    "\n",
    "        for i, (ic, sc, dc) in enumerate(zip(in_channels, skip_channels, decoder_channels)):\n",
    "            # print(i, ic, sc, dc)\n",
    "            self.blocks.append(\n",
    "                DecoderBlock2d(\n",
    "                    ic, sc, dc, \n",
    "                    norm_layer= norm_layer,\n",
    "                    attention_type= attention_type,\n",
    "                    intermediate_conv= intermediate_conv,\n",
    "                    upsample_mode= upsample_mode,\n",
    "                    scale_factor= scale_factors[i],\n",
    "                    )\n",
    "            )\n",
    "\n",
    "    def forward(self, feats: list[torch.Tensor]):\n",
    "        res= [feats[0]]\n",
    "        feats= feats[1:]\n",
    "\n",
    "        # Decoder blocks\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            skip= feats[i] if i < len(feats) else None\n",
    "            res.append(\n",
    "                b(res[-1], skip=skip),\n",
    "                )\n",
    "            \n",
    "        return res\n",
    "\n",
    "class SegmentationHead2d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        scale_factor: tuple[int] = (2,2),\n",
    "        kernel_size: int = 3,\n",
    "        mode: str = \"nontrainable\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv= nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size= kernel_size,\n",
    "            padding= kernel_size//2\n",
    "        )\n",
    "        self.upsample = UpSample(\n",
    "            spatial_dims= 2,\n",
    "            in_channels= out_channels,\n",
    "            out_channels= out_channels,\n",
    "            scale_factor= scale_factor,\n",
    "            mode= mode,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "#############\n",
    "## Encoder ##\n",
    "#############\n",
    "\n",
    "def _convnext_block_forward(self, x):\n",
    "    shortcut = x\n",
    "    x = self.conv_dw(x)\n",
    "\n",
    "    if self.use_conv_mlp:\n",
    "        x = self.norm(x)\n",
    "        x = self.mlp(x)\n",
    "    else:\n",
    "        x = self.norm(x)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = x.contiguous()\n",
    "        x = self.mlp(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = x.contiguous()\n",
    "\n",
    "    if self.gamma is not None:\n",
    "        x = x * self.gamma.reshape(1, -1, 1, 1)\n",
    "\n",
    "    x = self.drop_path(x) + self.shortcut(shortcut)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: str,\n",
    "        pretrained: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.backbone= timm.create_model(\n",
    "            backbone,\n",
    "            in_chans= 5,\n",
    "            pretrained= pretrained,\n",
    "            features_only= True,\n",
    "            drop_path_rate=0.0,\n",
    "            )\n",
    "        ecs= [_[\"num_chs\"] for _ in self.backbone.feature_info][::-1]\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder= UnetDecoder2d(\n",
    "            encoder_channels= ecs,\n",
    "        )\n",
    "\n",
    "        self.seg_head= SegmentationHead2d(\n",
    "            in_channels= self.decoder.decoder_channels[-1],\n",
    "            out_channels= 1,\n",
    "            scale_factor= 1,\n",
    "        )\n",
    "        \n",
    "        self._update_stem(backbone)\n",
    "        \n",
    "        self.replace_activations(self.backbone, log=True)\n",
    "        self.replace_norms(self.backbone, log=True)\n",
    "        self.replace_forwards(self.backbone, log=True)\n",
    "\n",
    "    def _update_stem(self, backbone):\n",
    "        if backbone.startswith(\"convnext\"):\n",
    "\n",
    "            # Update stride\n",
    "            self.backbone.stem_0.stride = (4, 1)\n",
    "            self.backbone.stem_0.padding = (0, 2)\n",
    "\n",
    "            # Duplicate stem layer (to downsample height)\n",
    "            with torch.no_grad():\n",
    "                w = self.backbone.stem_0.weight\n",
    "                out_ch = w.shape[0]\n",
    "                in_ch = w.shape[1]\n",
    "                new_conv = nn.Conv2d(out_ch, out_ch, kernel_size=(4, 4), stride=(4, 1), padding=(0, 1))\n",
    "                # è¿™é‡Œ repeat çš„ç¬¬äºŒä¸ªå‚æ•°è¦æ ¹æ® in_channels\n",
    "                repeat_factor = -(-out_ch // in_ch)  # å‘ä¸Šå–æ•´\n",
    "                rep_weight = w.repeat(1, repeat_factor, 1, 1)[:, :out_ch, :, :]\n",
    "                assert rep_weight.shape == new_conv.weight.shape, f\"{rep_weight.shape} != {new_conv.weight.shape}\"\n",
    "                new_conv.weight.copy_(rep_weight)\n",
    "                new_conv.bias.copy_(self.backbone.stem_0.bias)\n",
    "            \n",
    "                # new_conv= nn.Conv2d(w.shape[0], w.shape[0], kernel_size=(4, 4), stride=(4, 1), padding=(0, 1))\n",
    "                # new_conv.weight.copy_(w.repeat(1, (128//w.shape[1])+1, 1, 1)[:, :new_conv.weight.shape[1], :, :])\n",
    "                # new_conv.bias.copy_(self.backbone.stem_0.bias)\n",
    "\n",
    "            self.backbone.stem_0= nn.Sequential(\n",
    "                nn.ReflectionPad2d((1,1,80,80)),\n",
    "                self.backbone.stem_0,\n",
    "                new_conv,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Custom striding not implemented.\")\n",
    "        pass\n",
    "\n",
    "    def replace_activations(self, module, log=False):\n",
    "        if log:\n",
    "            print(f\"Replacing all activations with GELU...\")\n",
    "        \n",
    "        # Apply activations\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, (\n",
    "                nn.ReLU, nn.LeakyReLU, nn.Mish, nn.Sigmoid, \n",
    "                nn.Tanh, nn.Softmax, nn.Hardtanh, nn.ELU, \n",
    "                nn.SELU, nn.PReLU, nn.CELU, nn.GELU, nn.SiLU,\n",
    "            )):\n",
    "                setattr(module, name, nn.GELU())\n",
    "            else:\n",
    "                self.replace_activations(child)\n",
    "\n",
    "    def replace_norms(self, mod, log=False):\n",
    "        if log:\n",
    "            print(f\"Replacing all norms with InstanceNorm...\")\n",
    "            \n",
    "        for name, c in mod.named_children():\n",
    "\n",
    "            # Get feature size\n",
    "            n_feats= None\n",
    "            if isinstance(c, (nn.BatchNorm2d, nn.InstanceNorm2d)):\n",
    "                n_feats= c.num_features\n",
    "            elif isinstance(c, (nn.GroupNorm,)):\n",
    "                n_feats= c.num_channels\n",
    "            elif isinstance(c, (nn.LayerNorm,)):\n",
    "                n_feats= c.normalized_shape[0]\n",
    "\n",
    "            if n_feats is not None:\n",
    "                new = nn.InstanceNorm2d(\n",
    "                    n_feats,\n",
    "                    affine=True,\n",
    "                    )\n",
    "                setattr(mod, name, new)\n",
    "            else:\n",
    "                self.replace_norms(c)\n",
    "\n",
    "    def replace_forwards(self, mod, log=False):\n",
    "        if log:\n",
    "            print(f\"Replacing forward functions...\")\n",
    "            \n",
    "        for name, c in mod.named_children():\n",
    "            if isinstance(c, ConvNeXtBlock):\n",
    "                c.forward = MethodType(_convnext_block_forward, c)\n",
    "            else:\n",
    "                self.replace_forwards(c)\n",
    "\n",
    "        \n",
    "    def proc_flip(self, x_in):\n",
    "        x_in= torch.flip(x_in, dims=[-3, -1])\n",
    "        x= self.backbone(x_in)\n",
    "        x= x[::-1]\n",
    "\n",
    "        # Decoder\n",
    "        x= self.decoder(x)\n",
    "        x_seg= self.seg_head(x[-1])\n",
    "        x_seg= x_seg[..., 1:-1, 1:-1]\n",
    "        x_seg= torch.flip(x_seg, dims=[-1])\n",
    "        x_seg= x_seg * 1500 + 3000\n",
    "        return x_seg\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x= batch\n",
    "\n",
    "        # Encoder\n",
    "        x_in = x\n",
    "        x= self.backbone(x)\n",
    "        # print([_.shape for _ in x])\n",
    "        x= x[::-1]\n",
    "\n",
    "        # Decoder\n",
    "        x= self.decoder(x)\n",
    "        # print([_.shape for _ in x])\n",
    "        x_seg= self.seg_head(x[-1])\n",
    "        x_seg= x_seg[..., 1:-1, 1:-1]\n",
    "        x_seg= x_seg * 1500 + 3000\n",
    "    \n",
    "        if self.training:\n",
    "            return x_seg\n",
    "        else:\n",
    "            p1 = self.proc_flip(x_in)\n",
    "            x_seg = torch.mean(torch.stack([x_seg, p1]), dim=0)\n",
    "            return x_seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33f4934",
   "metadata": {
    "papermill": {
     "duration": 0.004265,
     "end_time": "2025-05-22T15:58:45.269979",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.265714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utils\n",
    "\n",
    "Same as starter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5f5b77e",
   "metadata": {
    "papermill": {
     "duration": 0.009881,
     "end_time": "2025-05-22T15:58:45.284245",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.274364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting _utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile _utils.py\n",
    "\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e099f831",
   "metadata": {
    "papermill": {
     "duration": 0.004239,
     "end_time": "2025-05-22T15:58:45.292908",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.288669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train\n",
    "\n",
    "Same as starter notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eaf948",
   "metadata": {
    "papermill": {
     "duration": 0.014208,
     "end_time": "2025-05-22T15:58:45.311693",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.297485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting _train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile _train.py\n",
    "\n",
    "import os\n",
    "import time \n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from _cfg import cfg\n",
    "from _dataset import CustomDataset\n",
    "from _model import ModelEMA, Net\n",
    "from _utils import format_time\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import logging\n",
    "\n",
    "import math\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"train_log.txt\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def set_seed(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    torch.cuda.set_device(rank)\n",
    "    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "    return\n",
    "\n",
    "def cleanup():\n",
    "    dist.barrier()\n",
    "    dist.destroy_process_group()\n",
    "    return\n",
    "\n",
    "def main(cfg):\n",
    "\n",
    "    # ========== Datasets / Dataloaders ==========\n",
    "    if cfg.local_rank == 0:\n",
    "        print(\"=\"*25)\n",
    "        print(\"Loading data..\")\n",
    "    train_ds = CustomDataset(cfg=cfg, mode=\"train\")\n",
    "    sampler= DistributedSampler(\n",
    "        train_ds, \n",
    "        num_replicas=cfg.world_size, \n",
    "        rank=cfg.local_rank,\n",
    "    )\n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        train_ds, \n",
    "        sampler= sampler,\n",
    "        batch_size= cfg.batch_size, \n",
    "        num_workers= 4,\n",
    "    )\n",
    "    \n",
    "    valid_ds = CustomDataset(cfg=cfg, mode=\"valid\")\n",
    "    sampler= DistributedSampler(\n",
    "        valid_ds, \n",
    "        num_replicas=cfg.world_size, \n",
    "        rank=cfg.local_rank,\n",
    "    )\n",
    "    valid_dl = torch.utils.data.DataLoader(\n",
    "        valid_ds, \n",
    "        sampler= sampler,\n",
    "        batch_size= cfg.batch_size_val, \n",
    "        num_workers= 4,\n",
    "    )\n",
    "\n",
    "    # ========== Model / Optim ==========\n",
    "    model = Net(backbone=cfg.backbone)\n",
    "\n",
    "    # state_dict= torch.load(\"best_model_123_last.pt\", map_location=cfg.device, weights_only=True)\n",
    "    # state_dict= {k.removeprefix(\"_orig_mod.\"):v for k,v in state_dict.items()} # Remove torch.compile() prefix\n",
    "    \n",
    "    # model.load_state_dict(state_dict)\n",
    "\n",
    "    model= model.to(cfg.local_rank)\n",
    "    model = torch.compile(model, mode=\"max-autotune\")\n",
    "    \n",
    "    if cfg.ema:\n",
    "        if cfg.local_rank == 0:\n",
    "            print(\"Initializing EMA model..\")\n",
    "        ema_model = ModelEMA(\n",
    "            model, \n",
    "            decay=cfg.ema_decay, \n",
    "            device=cfg.local_rank,\n",
    "        )\n",
    "    else:\n",
    "        ema_model = None\n",
    "    model= DistributedDataParallel(\n",
    "        model, \n",
    "        device_ids=[cfg.local_rank], \n",
    "        )\n",
    "    \n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, fused=True)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=3, min_lr=1e-8)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "\n",
    "    # ========== Training ==========\n",
    "    if cfg.local_rank == 0:\n",
    "        logging.info(\"=\"*25)\n",
    "        logging.info(\"Give me warp {}, Mr. Sulu.\".format(cfg.world_size))\n",
    "        logging.info(\"=\"*25)\n",
    "    \n",
    "    best_loss= 1_000_000\n",
    "    val_loss= 1_000_000\n",
    "\n",
    "    for epoch in range(0, cfg.epochs+1):\n",
    "        if epoch != 0:\n",
    "            tstart= time.time()\n",
    "            train_dl.sampler.set_epoch(epoch)\n",
    "    \n",
    "            # Train loop\n",
    "            model.train()\n",
    "            total_loss = []\n",
    "            for i, (x, y) in enumerate(train_dl):\n",
    "                x = x.to(cfg.local_rank)\n",
    "                y = y.to(cfg.local_rank)\n",
    "        \n",
    "                with autocast(device_type=cfg.device.type, dtype=torch.bfloat16):\n",
    "                    logits = model(x)\n",
    "                    \n",
    "                loss = criterion(logits, y)\n",
    "        \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.unscale_(optimizer)\n",
    "        \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 3.0)\n",
    "        \n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "    \n",
    "                total_loss.append(loss.item())\n",
    "                \n",
    "                if ema_model is not None:\n",
    "                    ema_model.update(model)\n",
    "                    \n",
    "                if cfg.local_rank == 0 and (len(total_loss) >= cfg.logging_steps or i == 0):\n",
    "                    train_loss = np.mean(total_loss)\n",
    "                    total_loss = []\n",
    "                    logging.info(\"Epoch {}:     Train MAE: {:.2f}     Val MAE: {:.2f}     Time: {}     Step: {}/{}\".format(\n",
    "                        epoch, \n",
    "                        train_loss,\n",
    "                        val_loss,\n",
    "                        format_time(time.time() - tstart),\n",
    "                        i+1, \n",
    "                        len(train_dl)+1, \n",
    "                    ))\n",
    "    \n",
    "        # ========== Valid ==========\n",
    "        model.eval()\n",
    "        val_logits = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(valid_dl, disable=cfg.local_rank != 0):\n",
    "                x = x.to(cfg.local_rank)\n",
    "                y = y.to(cfg.local_rank)\n",
    "    \n",
    "                with autocast(device_type=cfg.device.type, dtype=torch.bfloat16):\n",
    "                    if ema_model is not None:\n",
    "                        out = ema_model.module(x)\n",
    "                    else:\n",
    "                        out = model(x)\n",
    "\n",
    "                val_logits.append(out.cpu())\n",
    "                val_targets.append(y.cpu())\n",
    "\n",
    "            val_logits= torch.cat(val_logits, dim=0)\n",
    "            val_targets= torch.cat(val_targets, dim=0)\n",
    "                \n",
    "            loss = criterion(val_logits, val_targets).item()\n",
    "\n",
    "        # Gather loss\n",
    "        v = torch.tensor([loss], device=cfg.local_rank)\n",
    "        torch.distributed.all_reduce(v, op=dist.ReduceOp.SUM)\n",
    "        val_loss = (v[0] / cfg.world_size).item()\n",
    "\n",
    "        scheduler.step(val_loss) \n",
    "\n",
    "        if cfg.local_rank == 0:\n",
    "            logging.info(f\"[Epoch {epoch}] lr: {scheduler.get_last_lr()[0]:.9e}\")\n",
    "    \n",
    "        # ========== Weights / Early stopping ==========\n",
    "        stop_train = torch.tensor([0], device=cfg.local_rank)\n",
    "        if cfg.local_rank == 0:\n",
    "            es= cfg.early_stopping\n",
    "            if val_loss < best_loss:\n",
    "                logging.info(\"New best: {:.2f} -> {:.2f}\".format(best_loss, val_loss))\n",
    "                logging.info(\"Saved weights..\")\n",
    "                best_loss = val_loss\n",
    "                if ema_model is not None:\n",
    "                    torch.save(ema_model.module.state_dict(), f'best_model_{cfg.seed}.pt')\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), f'best_model_{cfg.seed}.pt')\n",
    "        \n",
    "                es[\"streak\"] = 0\n",
    "            else:\n",
    "                es= cfg.early_stopping\n",
    "                es[\"streak\"] += 1\n",
    "                if es[\"streak\"] > es[\"patience\"]:\n",
    "                    logging.info(\"Ending training (early_stopping).\")\n",
    "                    stop_train = torch.tensor([1], device=cfg.local_rank)\n",
    "        \n",
    "        # Exits training on all ranks\n",
    "        dist.broadcast(stop_train, src=0)\n",
    "        if stop_train.item() == 1:\n",
    "            return\n",
    "\n",
    "    return\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # GPU Specs\n",
    "    rank = int(os.environ[\"RANK\"])\n",
    "    world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "    _, total = torch.cuda.mem_get_info(device=rank)\n",
    "\n",
    "    # Init\n",
    "    setup(rank, world_size)\n",
    "    time.sleep(rank)\n",
    "    print(f\"Rank: {rank}, World size: {world_size}, GPU memory: {total / 1024**3:.2f}GB\", flush=True)\n",
    "    time.sleep(world_size - rank)\n",
    "\n",
    "    # Seed\n",
    "    set_seed(cfg.seed+rank)\n",
    "\n",
    "    # Run\n",
    "    cfg.local_rank= rank\n",
    "    cfg.world_size= world_size\n",
    "    main(cfg)\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444367b",
   "metadata": {
    "papermill": {
     "duration": 0.010406,
     "end_time": "2025-05-22T15:58:45.329635",
     "exception": false,
     "start_time": "2025-05-22T15:58:45.319229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..\n",
      "Rank: 0, World size: 2, GPU memory: 23.53GB\n",
      "Rank: 1, World size: 2, GPU memory: 23.53GB\n",
      "=========================\n",
      "Loading data..\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 920/920 [00:00<00:00, 1328.07it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:00<00:00, 1960.96it/s]\n",
      "2025-06-19 12:17:46,813 Loading pretrained weights from Hugging Face hub (timm/convnextv2_large.fcmae_ft_in22k_in1k_384)\n",
      "2025-06-19 12:17:47,502 Loading pretrained weights from Hugging Face hub (timm/convnextv2_large.fcmae_ft_in22k_in1k_384)\n",
      "2025-06-19 12:17:47,783 [timm/convnextv2_large.fcmae_ft_in22k_in1k_384] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-06-19 12:17:47,822 Converted input conv stem.0 pretrained weights from 3 to 5 channel(s)\n",
      "2025-06-19 12:17:48,003 [timm/convnextv2_large.fcmae_ft_in22k_in1k_384] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "2025-06-19 12:17:48,012 Converted input conv stem.0 pretrained weights from 3 to 5 channel(s)\n",
      "2025-06-19 12:17:48,059 Missing keys (head.fc.weight, head.fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "2025-06-19 12:17:48,060 Missing keys (head.fc.weight, head.fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\n",
      "Replacing all activations with GELU...\n",
      "Replacing all norms with InstanceNorm...\n",
      "Replacing forward functions...\n",
      "Replacing all activations with GELU...\n",
      "Replacing all norms with InstanceNorm...\n",
      "Replacing forward functions...\n",
      "Initializing EMA model..\n",
      "2025-06-19 12:17:50,140 =========================\n",
      "2025-06-19 12:17:50,141 Give me warp 2, Mr. Sulu.\n",
      "2025-06-19 12:17:50,141 =========================\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 313/313 [00:56<00:00,  5.55it/s]\n",
      "2025-06-19 12:18:46,930 [Epoch 0] lr: 5.000000000e-05\n",
      "2025-06-19 12:18:46,931 New best: 1000000.00 -> 37.32\n",
      "2025-06-19 12:18:46,931 Saved weights..\n"
     ]
    }
   ],
   "source": [
    "if RUN_TRAIN:\n",
    "    print(\"Starting training..\")\n",
    "    !OMP_NUM_THREADS=1 torchrun --nproc_per_node=2 _train.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11756775,
     "sourceId": 39763,
     "sourceType": "competition"
    },
    {
     "datasetId": 7253205,
     "sourceId": 11568812,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253605,
     "sourceId": 11569667,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7253661,
     "sourceId": 11569755,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7377931,
     "sourceId": 11887338,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7487776,
     "sourceId": 11910577,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2170.364556,
   "end_time": "2025-05-22T16:34:42.030060",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-22T15:58:31.665504",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
